{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 스크래핑한 데이터를 인공지능이 학습하도록 전처리합니다.\n",
    "\n",
    "설치시 필요한 것\n",
    "- konlpy\n",
    "- gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\dev-tensorflow\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Twitter\n",
    "from os import makedirs\n",
    "import gensim\n",
    "import tensorflow as tf\n",
    "import codecs\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = \"../data/ratings_train.txt\"\n",
    "TEST_DATA = \"../data/ratings_test.txt\"\n",
    "MODEL_DATA = \"../data/word2vec.model\"\n",
    "WORD2VEC_PATH = \"../data/word2vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):    \n",
    "    with open(filename, 'r',encoding='utf-8') as fp:\n",
    "        data = [line.split('\\t') for line in fp.read().splitlines()]        \n",
    "        data = data[1:]   # header 제외 #    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data(TRAIN_DATA)\n",
    "test_data = read_data(TEST_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 품사 태깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pos_tagger = Twitter()\n",
    "\n",
    "def tokenize(doc):\n",
    "    return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## id, review, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 품사 태깅 (Twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [tokenize(row[1]) for row in train_data]\n",
    "tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 워드 임베딩\n",
    " - min_alpha : training 됨에 따라 줄어든 learning_rate\n",
    " - alpha : initial learning rate\n",
    " - learning_rate decay 해줌\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(size=300, sg = 1, alpha=0.025, min_alpha=0.025, seed=1234)\n",
    "model.build_vocab(tokens)\n",
    "\n",
    "for epoch in range(30):           \n",
    "    model.train(tokens,model.corpus_count,epochs = model.iter)\n",
    "    model.alpha -= 0.002\n",
    "    model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_DATA)\n",
    "model.most_similar('영화/Noun',topn = 20)  ## topn = len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 결과 확인 (Tensor board 로 보기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\dev-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('../Punctuation', 0.9061493873596191),\n",
       " ('하다/Verb', 0.8798155784606934),\n",
       " ('이/Josa', 0.8764169216156006),\n",
       " ('없다/Adjective', 0.8203310966491699),\n",
       " ('들/Suffix', 0.807205080986023),\n",
       " ('판타지영화/Noun', -0.31531190872192383),\n",
       " ('뮤지컬영화/Noun', -0.3252159059047699),\n",
       " ('멜로영화/Noun', -0.3374733328819275),\n",
       " ('남아돌다/Verb', -0.33805131912231445),\n",
       " ('5~6/Number', -0.3385058343410492),\n",
       " ('폰부스/Noun', -0.3392675518989563),\n",
       " ('겄/Noun', -0.3432907164096832),\n",
       " ('잉여/Noun', -0.3456770181655884),\n",
       " ('만인/Noun', -0.35029393434524536),\n",
       " ('손해/Noun', -0.3512357473373413),\n",
       " ('화만/Noun', -0.35157400369644165),\n",
       " ('방학/Noun', -0.35220322012901306),\n",
       " ('만화영화/Noun', -0.3524870276451111),\n",
       " ('공포물/Noun', -0.352843701839447),\n",
       " ('호러영화/Noun', -0.35320329666137695)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_model = gensim.models.Word2Vec.load(MODEL_DATA)\n",
    "view_model.most_similar('영화/Noun', topn = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\dev-tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `layer1_size` (Attribute will be removed in 4.0.0, use self.trainables.layer1_size instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "max_size = len(view_model.wv.vocab)-1\n",
    "w2v = np.zeros((max_size, view_model.layer1_size))\n",
    "\n",
    "if not os.path.exists('../data/word2vec'):\n",
    "    makedirs('../data/word2vec')\n",
    "    \n",
    "with codecs.open('../data/word2vec/metadata.tsv','w+',encoding='utf8') as fp:\n",
    "    for i,word in enumerate(view_model.wv.index2word[:max_size]):\n",
    "        w2v[i] = view_model.wv[word]\n",
    "        fp.write(word + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "##  Create 2D tensor called embedding that holds our embeddings ##  \n",
    "with tf.device(\"/cpu:0\"):\n",
    "    embedding = tf.Variable(w2v, trainable = False,  name = 'embedding')   \n",
    "\n",
    "tf.global_variables_initializer().run() \n",
    "\n",
    "path = WORD2VEC_PATH\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "writer = tf.summary.FileWriter(path, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding into project\n",
    "config = projector.ProjectorConfig()\n",
    "embed = config.embeddings.add()\n",
    "embed.tensor_name = 'embedding'\n",
    "embed.metadata_path = 'metadata.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/word2vec/model.ckpt-15408'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the width and height of a single thumbnail.\n",
    "projector.visualize_embeddings(writer, config)\n",
    "saver.save(sess, path + '/model.ckpt' , global_step=max_size)\n",
    "## cmd 실행후 -> 1. cd [소스실행경로]\\data\n",
    "##              2. tensorboard --logdir=./word2vec 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
